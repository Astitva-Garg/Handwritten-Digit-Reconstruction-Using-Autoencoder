# Autoencoders on MNIST

This repository contains two implementations of **Autoencoders** trained on the [MNIST dataset](http://yann.lecun.com/exdb/mnist/) using **PyTorch**:

1. **Linear Autoencoder** â€“ uses fully connected layers to compress and reconstruct the 28Ã—28 MNIST digits.  
2. **Convolutional Autoencoder** â€“ uses convolutional and transposed convolutional layers for better spatial feature extraction and reconstruction.

Both models learn to encode handwritten digits into a compressed latent space and decode them back to images.

---

## What is an Autoencoder?
An **Autoencoder** is an unsupervised neural network that learns to reconstruct its input.  
It consists of:
- **Encoder** â€“ reduces the input dimensionality (compression).
- **Decoder** â€“ reconstructs the input from the compressed representation.

The learning objective is to minimize the reconstruction loss (here, **Mean Squared Error**).

---

## Repository Structure
```
â”œâ”€â”€ linear_autoencoder.py        # Autoencoder with fully connected layers
â”œâ”€â”€ conv_autoencoder.py          # Autoencoder with convolutional layers
â”œâ”€â”€ data/                        # MNIST dataset will be downloaded here
â””â”€â”€ README.md
```

---

## Requirements
Install the dependencies with:

```bash
pip install torch torchvision matplotlib
```

---

##  Usage

### 1. Train the Linear Autoencoder
```bash
python ae_torch.py
```

### 2. Train the Convolutional Autoencoder
```bash
python conv_ae_torch.py
```

During training, the script prints the **epoch loss** and visualizes reconstructed images after training.  

---

## ğŸ— Model Architectures

### ğŸ”¹ Linear Autoencoder
- **Encoder**:  
  `784 â†’ 128 â†’ 64 â†’ 12 â†’ 5`  
- **Decoder**:  
  `5 â†’ 12 â†’ 64 â†’ 128 â†’ 784`  

### ğŸ”¹ Convolutional Autoencoder
- **Encoder**:  
  `Conv2d(1â†’16) â†’ Conv2d(16â†’32) â†’ Conv2d(32â†’64)`  
- **Decoder**:  
  `ConvTranspose2d(64â†’32) â†’ ConvTranspose2d(32â†’16) â†’ ConvTranspose2d(16â†’1)`  

---

## Training Details
- **Dataset**: MNIST (28Ã—28 grayscale images)  
- **Loss Function**: Mean Squared Error (MSE)  
- **Optimizer**: Adam (lr=1e-3, weight_decay=1e-5)  
- **Batch Size**: 64  
- **Epochs**: 13  

---

## Results
After training, the models generate reconstructions of MNIST digits.  
For every 4 epochs, the code visualizes:

- **Top row**: Original images  
- **Bottom row**: Reconstructed images  

Example (illustrative layout):

```
+---------+---------+---------+     +---------+---------+---------+
| Original| Original| Original| ... | Reconst | Reconst | Reconst |
+---------+---------+---------+     +---------+---------+---------+
```

The convolutional autoencoder typically achieves sharper reconstructions compared to the linear one.

---

##  Notes
- The **linear autoencoder** flattens the images into vectors.  
- The **convolutional autoencoder** preserves spatial information using Conv2d layers, making it better at capturing digit structure.  

---

## License
This project is open-source and available under the **MIT License**.
